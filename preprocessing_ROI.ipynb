{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e146f34-847a-4370-93dd-6e6efbaad913",
   "metadata": {},
   "source": [
    "# Preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "456bd615-b312-41a7-84f5-5db03801a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import transform, util\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.measure import regionprops, label\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "def get_ROI(im,mask,res):\n",
    "    # Give as an input an image (in the form of a dictionary with labels 'img'and 'mask) \n",
    "    # and outputs an ROI centred around the centre of mass of the heart. \n",
    "    # Second input is the resolutoin (mm/pixel) of the input image.\n",
    "    \n",
    "    # # split input into image and mask\n",
    "    # im = image['img']                          \n",
    "    # mask = image['mask']\n",
    "    \n",
    "    # find target size of ROI, based on pixel size (mm/pixel) and maximum expected size of heart (doi: 10.15171/jcvtr.2016.25)\n",
    "    # nr = np.round(16/res[0]*10/2).astype(int) # number of rows/2\n",
    "    # nc = np.round(16/res[1]*10/2).astype(int) # number of columns/2\n",
    "    nr = int(128/2) # target size is 128 by 128 pixels\n",
    "    nc = int(128/2)\n",
    "    mask_single_class = np.copy(mask)\n",
    "    # mask_single_class = np.expand_dims(mask_single_class, axis=0)\n",
    "    # print(mask_single_class)\n",
    "    # print(np.shape(mask_single_class))\n",
    "    # print(np.where(mask_single_class!=0))\n",
    "    # print(np.unique(mask_single_class))\n",
    "    mask_single_class[mask_single_class!=0] = 1\n",
    "    if len(np.unique(mask_single_class))==1:                                            # if there is no heart in the image, just use the central part of the image as an ROI\n",
    "        labels = label(mask_single_class,background=1)                                  # find all connected components\n",
    "        largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1    # largest connected components\n",
    "        mask = largestCC*1                                                 # True --> 1, False --> 0     \n",
    "        properties = regionprops(mask)                                     # Geometrical properties of image\n",
    "        com = np.round(properties[0].centroid).astype(int)                 # Centre of mass = centre of image in this specific case\n",
    "        com_r = com[0]                                                     # row index\n",
    "        com_c = com[1]                                                     # column index\n",
    "        ROI_mask = mask[(com_r-nr):(com_r+nr),(com_c-nc):(com_c+nc)]     # ROI mask --> traget size 128*128 pixels\n",
    "        ROI_mask = 0*ROI_mask\n",
    "        ROI = im[(com_r-nr):(com_r+nr),(com_c-nc):(com_c+nc)]            # ROI of grey scale image\n",
    "\n",
    "    else:                                                                  # if heart is present\n",
    "        # Find Largest connected component:\n",
    "        labels = label(mask_single_class)                                  # find all connected components\n",
    "        largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1    # largest connected components\n",
    "        largestCC = largestCC*1                                            # True --> 1, False --> 0\n",
    "        properties = regionprops(largestCC)                                # Geometrical properties of largest connected component\n",
    "        com = np.round(properties[0].centroid).astype(int)                 # Centre of mass\n",
    "        com_r = com[0]                                                     # row index\n",
    "        com_c = com[1]                                                     # column index\n",
    "        ROI_mask = mask[(com_r-nr):(com_r+nr),(com_c-nc):(com_c+nc)]\n",
    "        # print(np.unique(ROI_mask))\n",
    "        ROI = im[(com_r-nr):(com_r+nr),(com_c-nc):(com_c+nc)]    \n",
    "    # plt.figure()\n",
    "    # plt.imshow(np.squeeze(ROI),'gray')\n",
    "    # overlay_mask = np.ma.masked_where(ROI_mask==0, ROI_mask)\n",
    "    # plt.imshow(overlay_mask, 'Reds', alpha = 0.5, clim=[0,1], interpolation='nearest')\n",
    "    # plt.scatter(x=nc, y=nr, c='g', s=40)\n",
    "    # plt.figure()\n",
    "    \n",
    "    return ROI,ROI_mask\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    # Warning for when dividing NaN value??\n",
    "    norm_img = np.divide(img,np.max(img))\n",
    "    return norm_img\n",
    "\n",
    "\n",
    "def crop_pad_resize(image, nx, ny):\n",
    "    x, y = image.shape\n",
    "\n",
    "    # difference in nr of pixels (divide by 2 since we have 2 sides)\n",
    "    x_s = (x - nx) // 2\n",
    "    y_s = (y - ny) // 2\n",
    "    x_c = (nx - x) // 2\n",
    "    y_c = (ny - y) // 2\n",
    "\n",
    "    if x > nx and y > ny:\n",
    "        # if image is larger in both dimensions cut a slice\n",
    "        slice_cropped = image[x_s:x_s + nx, y_s:y_s + ny]\n",
    "\n",
    "    else:\n",
    "        # if one dim is smaller fill that side up with 0's\n",
    "        slice_cropped = np.zeros((nx, ny))\n",
    "\n",
    "        if x <= nx and y > ny:\n",
    "            # fill up x direction with 0's, cut in x direction\n",
    "            slice_cropped[x_c:x_c + x, :] = image[:, y_s:y_s + ny]\n",
    "        elif x > nx and y <= ny:\n",
    "            # fill up y direction with 0's, cut in y direction\n",
    "            slice_cropped[:, y_c:y_c + y] = image[x_s:x_s + nx, :]\n",
    "        else:\n",
    "            # if dimensions are as desired, keep the original slice\n",
    "            slice_cropped[x_c:x_c + x, y_c:y_c + y] = image[:, :]\n",
    "\n",
    "    return slice_cropped\n",
    "\n",
    "\n",
    "def preprocess(input_folder, target_resolution, target_size, denoise=False, alphaTV=0.1):\n",
    "    '''\n",
    "    This function preprocesses ACDC data. It crops all images to the same size,\n",
    "    transforms everything to the same resolution and normalizes the images.\n",
    "    It automatically makes the folder where preprocessed data is written to,\n",
    "    in the same format as the ACDC data is given. The images are in PNG-format.\n",
    "    \n",
    "    input_folder: the folder where raw ACDC data is located.\n",
    "    target_resolution: desired resolution, should be a tuple with 2 items (x- and y-dimensions).\n",
    "    target_size: desired size. Should be a tuple wiht 2 items (x- and y-dimensions).\n",
    "    '''\n",
    "    corrupted_files = []\n",
    "    nx, ny = target_size\n",
    "    data_folder = input_folder\n",
    "    \n",
    "    if denoise:\n",
    "        foldername = 'preprocessed_ROI_TV005_v3'\n",
    "    else:\n",
    "        foldername = 'preprocessed_ROI_v3'\n",
    "    \n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # Loop over train and test folders\n",
    "    for train_test in ['training', 'testing']:\n",
    "\n",
    "        input_folder = os.path.join(data_folder, train_test)\n",
    "        len_inp = len(input_folder)+1\n",
    "        \n",
    "        # Make train and test folders in preprocessed folder\n",
    "        if not os.path.exists(os.path.join(foldername+'/', train_test)):\n",
    "            os.mkdir(os.path.join(foldername+'/', train_test))\n",
    "        else:\n",
    "            print('T'+train_test[1:]+' folder already exists. Continuing regardless.')\n",
    "        \n",
    "        # Loop over patient folders\n",
    "        for folder in os.listdir(input_folder):\n",
    "            \n",
    "            if folder != '.ipynb_checkpoints':  # Sometimes trouble with automatically made files\n",
    "\n",
    "                folder_path = os.path.join(input_folder, folder)\n",
    "                \n",
    "                # Make patient folders in preprocessed folder\n",
    "                if not os.path.exists(os.path.join(foldername+'/'+train_test, folder_path[len_inp:])):\n",
    "                    os.mkdir(os.path.join(foldername+'/'+train_test, folder_path[len_inp:]))\n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' already exists. Continuing regardless.')\n",
    "                \n",
    "                if os.path.exists(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints'):\n",
    "                    os.rmdir(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints')\n",
    "                    \n",
    "                lst = os.listdir(foldername+'/'+train_test+'/'+folder_path[len_inp:])\n",
    "                \n",
    "                if len(lst) == 0:  # Only create files if the designated folder is empty\n",
    "                    \n",
    "                    for file in glob.glob(os.path.join(folder_path, 'patient???_frame??.nii.gz')):\n",
    "\n",
    "                        # Save information about patient\n",
    "                        with open(os.path.join(folder_path, 'Info.cfg')) as f:\n",
    "                            lines = f.readlines()\n",
    "\n",
    "                        ED = int(lines[0].strip()[-2:])\n",
    "                        ES = int(lines[1].strip()[-2:])\n",
    "\n",
    "                        # Split file name\n",
    "                        file_base = file.split('.nii.gz')[0]\n",
    "                        file_mask = file_base + '_gt.nii.gz'\n",
    "\n",
    "                        # Load data from .nii.gz files\n",
    "                        img_nii = nib.load(file)\n",
    "                        img_dat = img_nii.get_fdata()\n",
    "\n",
    "                        mask_nii = nib.load(file_mask)\n",
    "                        mask_dat = mask_nii.get_fdata().astype(int)\n",
    "                        \n",
    "                        if(np.logical_or('patient038' in file , 'patient057' in file)):\n",
    "                            print(np.unique(mask_dat))\n",
    "\n",
    "\n",
    "                        img = img_nii.get_fdata()\n",
    "                        mask = mask_nii.get_fdata()\n",
    "\n",
    "                        pixel_size = img_nii.header.get_zooms()\n",
    "\n",
    "                        # Make vector to make all images have the same resolution\n",
    "                        scale_vector = [pixel_size[0] / target_resolution[0], pixel_size[1] / target_resolution[1]] \n",
    "\n",
    "                        for zz in tqdm.tqdm(range(img.shape[2])):\n",
    "\n",
    "                            # Normalize, rescale and crop the image and  mask\n",
    "\n",
    "                            slice_img = np.squeeze(img[:, :, zz])\n",
    "                            slice_img = normalize_img(np.squeeze(img[:, :, zz]))\n",
    "                            #slice_img = np.squeeze(img[:, :, zz])\n",
    "                            img_rescaled = transform.rescale(slice_img,\n",
    "                                                             scale_vector,\n",
    "                                                             order=1,\n",
    "                                                             preserve_range=True,\n",
    "                                                             mode='constant')\n",
    "\n",
    "                            slice_mask = np.squeeze(mask[:, :, zz])\n",
    "                            # slice_mask = normalize_img(np.squeeze(mask[:, :, zz]))\n",
    "                            mask_rescaled = np.around(transform.rescale(slice_mask,\n",
    "                                                              scale_vector,\n",
    "                                                              order=0,\n",
    "                                                              preserve_range=True,\n",
    "                                                              mode='constant'))\n",
    "                            #print(np.unique(mask_rescaled))\n",
    "                            img_cropped = crop_pad_resize(img_rescaled, nx, ny)\n",
    "                            mask_cropped = crop_pad_resize(mask_rescaled, nx, ny)\n",
    "                                                       \n",
    "                            \n",
    "                            if(np.logical_or('patient038' in file , 'patient057' in file)):\n",
    "                                #print(np.unique(mask_rescaled))\n",
    "                                # print(file_base)\n",
    "                                corrupted_files.append(file_base)\n",
    "                            else:\n",
    "                                # Find largest connected component:\n",
    "                                img_cropped,mask_cropped=get_ROI(img_cropped,mask_cropped,target_resolution)\n",
    "                                \n",
    "                            if denoise:\n",
    "                                img_cropped = denoise_tv_chambolle(img_cropped, eps=1e-6, weight=alphaTV, max_num_iter=1000)\n",
    "                            \n",
    "                            if not (np.logical_or('patient038' in file , 'patient057' in file)):\n",
    "                                # Save images in PNG format\n",
    "                                if 'frame{:02}'.format(ED) in file:\n",
    "                                    img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED'.format(zz)+'.png')\n",
    "                                    img_fin = Image.fromarray(np.uint8(255*img_cropped),mode=\"L\")\n",
    "                                    img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "                                    mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED_gt'.format(zz)+'.png')\n",
    "                                    mask_fin = Image.fromarray(np.uint8(mask_cropped), mode=\"L\")\n",
    "                                    #print('uniquecrop'+ str(np.uint8(np.unique(mask_cropped))))\n",
    "                                    mask_fin.save(mask_loc, format='PNG')\n",
    "                                else:\n",
    "                                    img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES'.format(zz)+'.png')\n",
    "                                    img_fin = Image.fromarray(np.uint8(255*img_cropped), mode=\"L\")\n",
    "                                    img_fin.save(img_loc, format='PNG')\n",
    "                                    \n",
    "                                    #print(np.shape(mask_cropped))\n",
    "                                    mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES_gt'.format(zz)+'.png')\n",
    "                                    mask_fin = Image.fromarray(np.uint8(mask_cropped),mode=\"L\")\n",
    "                                    mask_fin.save(mask_loc, format='PNG')\n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' is not empty. No files were written to this folder.')\n",
    "        \n",
    "    # print(corrupted_files)\n",
    "    print(\"Preprocessing Finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbca9d3-6919-4562-b86c-dd2e32944bac",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c785ee5-f3a6-4c21-a1bc-ab3776dca597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.64it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.87it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 12.79it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 15.36it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  9.18it/s]\n",
      "100%|██████████| 11/11 [00:01<00:00,  8.36it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 28.76it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 30.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.23it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 20.71it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 18.59it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 19.19it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.63it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 17.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22.47it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.39it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 12.85it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 14.84it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.88it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  8.73it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.06it/s]\n",
      "100%|██████████| 18/18 [00:01<00:00, 15.20it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 16.30it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 23.70it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 17.90it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 21.10it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 20.21it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 43.66it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 37.04it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 15.44it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00,  7.97it/s]\n",
      "100%|██████████| 7/7 [00:01<00:00,  6.22it/s]\n",
      " 50%|█████     | 5/10 [00:00<00:00, 10.41it/s]"
     ]
    }
   ],
   "source": [
    "target_resolution = (1.36719, 1.36719)\n",
    "target_size = (256, 256)\n",
    "data_path = './Data/database'\n",
    "\n",
    "#preprocess(data_path, target_resolution, target_size)\n",
    "preprocess(data_path, target_resolution, target_size, denoise=True, alphaTV=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240090-a4ba-43d3-838d-78462f1f2e9a",
   "metadata": {},
   "source": [
    "#### Denoise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc831d0-c58b-492d-bac7-dbdf0d0f6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(data_path, target_resolution, target_size, denoise=True, alphaTV=0.2)\n",
    "# alpha = 0.1 geeft wel prima maar nog veel details, 0.3 is misschien net hoog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06a56f-d604-4810-a7ea-f87a2a8a9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ik heb alpha =0.1 gekozen, target size veranderd naar 256*256 --> werkt beter icm onze kernal afmetingen en aantal lagen van netwerk, voor gecropte images gebruik ik een target size van 128*128\n",
    "\n",
    "# Voor ROI alpha verlaagd naar 0.05 ---> toch naar 0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
