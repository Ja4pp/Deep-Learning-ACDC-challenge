{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88e1707-e10f-46da-9392-b94ea36bc40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import monai\n",
    "from PIL import Image\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from monai.apps import CrossValidation\n",
    "from abc import ABC, abstractmethod\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d28cf22-416d-47d2-957f-56101f87d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats! You selected the correct folder :)\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./preprocessed/\"\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Please update your data path to an existing folder.\")\n",
    "elif not set([\"training\", \"testing\"]).issubset(set(os.listdir(data_path))):\n",
    "    print(\"Please update your data path to the correct folder (should contain training and testing folders).\")\n",
    "else:\n",
    "    print(\"Congrats! You selected the correct folder :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b274424d-20fc-4ced-9648-3a5998575666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVDataset(ABC, monai.data.CacheDataset):\n",
    "    \"\"\"\n",
    "    Base class to generate cross validation datasets.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        transform,\n",
    "        cache_num=sys.maxsize,\n",
    "        cache_rate=1.0,\n",
    "        num_workers=4,\n",
    "    ) -> None:\n",
    "        data = self._split_datalist(datalist=data)\n",
    "        monai.data.CacheDataset.__init__(\n",
    "            self, data, transform, cache_num=cache_num, cache_rate=cache_rate, num_workers=num_workers\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def _split_datalist(self, datalist):\n",
    "        raise NotImplementedError(f\"Subclass {self.__class__.__name__} must implement this method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c75c204-8133-4584-8046-ab7a0894587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(img.header.structarr['pixdim'])\n",
    "\n",
    "def build_dict_ACDC(data_path, modes='training', heart_mode='Off'):\n",
    "    \"\"\"\n",
    "    This function returns a list of dictionaries, each dictionary containing the keys 'img' and 'mask' \n",
    "    that returns the path to the corresponding image.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): path to the root folder of the data set.\n",
    "        modes (str): subset used. Must correspond to 'training', 'val' or 'testing'.\n",
    "        \n",
    "    Returns:\n",
    "        (List[Dict[str, str]]) list of the dictionaries containing the paths of X-ray images and masks.\n",
    "    \"\"\"\n",
    "    # test if mode is correct\n",
    "    if modes not in [\"training\", \"val\", \"testing\", \"all\"]:\n",
    "        raise ValueError(f\"Please choose a mode in ['training', 'val', 'testing', 'all']. Current mode is {mode}.\")\n",
    "    \n",
    "    # define empty dictionary\n",
    "    dicts = []\n",
    "    dicts2 = []\n",
    "    paths_mri = []\n",
    "    iBegin = 1\n",
    "    iEnd = 101\n",
    "    \n",
    "    if(modes==\"all\"):\n",
    "        modes= ['training', 'testing']\n",
    "    else:\n",
    "        modes = [modes]\n",
    "    \n",
    "    for mode in modes:\n",
    "\n",
    "        if (mode=='testing'):\n",
    "            iBegin = 101\n",
    "            iEnd = 151\n",
    "\n",
    "        for i in tqdm(range(iBegin,iEnd)):\n",
    "            \n",
    "                # list all .png files in directory, including the path\n",
    "                paths_mri.append(glob.glob(os.path.join(data_path, mode, 'patient{:03}'.format(i), '*[!gt].png')))\n",
    "                \n",
    "                # print(os.path.join(data_path, mode, 'patient{:03}'.format(i), '*[!gt].png'))\n",
    "                # make a corresponding list for all the mask files\n",
    "                for mri_path in paths_mri[0]:\n",
    "                    if mode == 'testing':\n",
    "                        suffix = 'val'\n",
    "                    else:\n",
    "                        suffix = mode\n",
    "\n",
    "                    mask_path = os.path.join(mri_path[0:-4]+'_gt'+ '.png')\n",
    "                    if os.path.exists(mask_path):\n",
    "                        if (heart_mode=='Off'):\n",
    "                            dicts.append({'img': mri_path, 'mask': mask_path})\n",
    "                        else:\n",
    "\n",
    "                            if 'ED' in mri_path:\n",
    "                                dicts.append({'img': mri_path, 'mask': mask_path})\n",
    "\n",
    "                            else:\n",
    "                                dicts2.append({'img': mri_path, 'mask': mask_path})\n",
    "\n",
    "                paths_mri.clear()        \n",
    "    if (heart_mode=='Off'):   \n",
    "        return dicts\n",
    "    else:\n",
    "        return dicts, dicts2\n",
    "\n",
    "                    \n",
    "All_data = build_dict_ACDC(data_path, modes=\"training\")\n",
    "# ES, ED = build_dict_ACDC(data_path, heart_mode=\"On\")\n",
    "# print(len(All_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919fa161-e149-4acc-b946-5c3540fe268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadMriData(monai.transforms.Transform):\n",
    "    \"\"\"\n",
    "    This custom Monai transform loads the data from the rib segmentation dataset.\n",
    "    Defining a custom transform is simple; just overwrite the __init__ function and __call__ function.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys=None):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = Image.open(sample['img']).convert('L') # import as grayscale image\n",
    "        # image = nib.load(sample['img']).get_fdata()\n",
    "        image = np.array(image, dtype=np.uint8)\n",
    "        mask = Image.open(sample['mask']).convert('L') # import as grayscale image\n",
    "        # mask = nib.load(sample['mask']).get_fdata()\n",
    "        mask = np.array(mask, dtype=np.uint8)\n",
    "        # slice = sample['slice']\n",
    "        # mask has value 255 on rib pixels. Convert to binary array\n",
    "        mask[np.logical_and(np.logical_and(mask!=85,mask!=170),mask!=255)] = 0\n",
    "        mask[np.where(mask==255)] = 1\n",
    "        mask[np.where(mask==85)] = 2\n",
    "        mask[np.where(mask==170)] = 3\n",
    "        # mask[np.where(mask>0 & mask <255)] = 0.5\n",
    "        return {'img': image, 'mask': mask, 'img_meta_dict': {'affine': np.eye(2)}, \n",
    "                'mask_meta_dict': {'affine': np.eye(2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea964451-2f16-4b9f-a21a-fd9f8b3da921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1950.39it/s]\n",
      "Loading dataset: 100%|██████████| 1521/1521 [00:06<00:00, 219.12it/s]\n",
      "Loading dataset: 100%|██████████| 1521/1521 [00:07<00:00, 205.15it/s]\n",
      "Loading dataset: 100%|██████████| 1522/1522 [00:07<00:00, 207.48it/s]\n",
      "Loading dataset: 100%|██████████| 1522/1522 [00:07<00:00, 207.18it/s]\n",
      "Loading dataset: 100%|██████████| 1522/1522 [00:07<00:00, 205.93it/s]\n",
      "Loading dataset: 100%|██████████| 381/381 [00:00<00:00, 561.95it/s]\n",
      "Loading dataset: 100%|██████████| 381/381 [00:00<00:00, 581.20it/s]\n",
      "Loading dataset: 100%|██████████| 380/380 [00:00<00:00, 891.87it/s]\n",
      "Loading dataset: 100%|██████████| 380/380 [00:00<00:00, 687.46it/s]\n",
      "Loading dataset: 100%|██████████| 380/380 [00:00<00:00, 687.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "train_dict_list = build_dict_ACDC(data_path)\n",
    "\n",
    "composed_transform = monai.transforms.Compose([LoadMriData(),\n",
    "                                                monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "                                                monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "                                                monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi, prob=6/7, mode=['bilinear', 'nearest'],padding_mode=['zeros','zeros']),\n",
    "                                                #monai.transforms.RandFlipd(keys=['img', 'mask'], prob=1/2, spatial_axis=1),  \n",
    "                                                ])\n",
    "\n",
    "val_transform = monai.transforms.Compose([LoadMriData(),\n",
    "                                                # monai.transforms.AddChanneld(keys=['img', 'mask']),\n",
    "                                                # monai.transforms.ScaleIntensityd(keys=['img'],minv=0, maxv=1),\n",
    "                                                # monai.transforms.RandRotated(keys=['img', 'mask'], range_x=np.pi, prob=6/7, mode=['bilinear', 'nearest'],padding_mode=['zeros','zeros']),\n",
    "                                                #monai.transforms.RandFlipd(keys=['img', 'mask'], prob=1/2, spatial_axis=1),  \n",
    "                                                ])\n",
    "# train_dataset = monai.data.CacheDataset(train_dict_list, transform=composed_transform)\n",
    "\n",
    "\n",
    "num = 5\n",
    "folds = list(range(num))\n",
    "\n",
    "cvdataset = CrossValidation(\n",
    "    dataset_cls=CVDataset,\n",
    "    data=train_dict_list,\n",
    "    nfolds=5,\n",
    "    seed=12345,\n",
    "    transform=composed_transform,\n",
    ")\n",
    "\n",
    "train_dss = [cvdataset.get_dataset(folds=folds[0:i] + folds[(i + 1) :]) for i in folds]\n",
    "val_dss = [cvdataset.get_dataset(folds=i, transform=val_transform) for i in range(num)]\n",
    "\n",
    "train_loaders = [monai.data.DataLoader(train_dss[i], batch_size=2, shuffle=True, num_workers=4) for i in folds]\n",
    "val_loaders = [monai.data.DataLoader(val_dss[i], batch_size=1, num_workers=4) for i in folds]\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac05585c-fd59-4673-9015-b5d419e355c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<monai.data.dataloader.DataLoader object at 0x7f8009686a00>, <monai.data.dataloader.DataLoader object at 0x7f80038b1fd0>, <monai.data.dataloader.DataLoader object at 0x7f8000d007f0>, <monai.data.dataloader.DataLoader object at 0x7f8000cf5a90>, <monai.data.dataloader.DataLoader object at 0x7f8000cf5310>]\n"
     ]
    }
   ],
   "source": [
    "print(train_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b229334-e67c-4f63-a044-aaf19dfd1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = nib.load(r'/home/jovyan/Desktop/Deep-Learning-ACDC-challenge/database/training/patient100/patient100_frame01_gt.nii.gz' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "987a2d5a-37ae-4c90-99e9-0bab7c0a0f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.313034 mm^3\n"
     ]
    }
   ],
   "source": [
    "sx, sy, sz  = image.header.get_zooms()\n",
    "volume_vox = sx*sy*sz\n",
    "print(str(volume_vox) + ' mm^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14343521-9663-4a13-9ac5-3eb15438e12e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
