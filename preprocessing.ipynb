{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e146f34-847a-4370-93dd-6e6efbaad913",
   "metadata": {},
   "source": [
    "# Preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456bd615-b312-41a7-84f5-5db03801a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import transform\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    # Warning for when dividing NaN value??\n",
    "    norm_img = np.divide(img,np.max(img))\n",
    "    return norm_img\n",
    "\n",
    "\n",
    "def crop_pad_resize(image, nx, ny):\n",
    "    '''\n",
    "    Code from Christian F. Baumgartner and Lisa M. Koch from\n",
    "    \"An Exploration of 2D and 3D Deep Learning Techniques for\n",
    "    Cardiac MR Image Segmentation\" (2017).\n",
    "    Comments by us.\n",
    "    '''\n",
    "    x, y = image.shape\n",
    "\n",
    "    # difference in nr of pixels (divide by 2 since we have 2 sides)\n",
    "    x_s = (x - nx) // 2\n",
    "    y_s = (y - ny) // 2\n",
    "    x_c = (nx - x) // 2\n",
    "    y_c = (ny - y) // 2\n",
    "\n",
    "    if x > nx and y > ny:\n",
    "        # if image is larger in both dimensions cut a slice\n",
    "        slice_cropped = image[x_s:x_s + nx, y_s:y_s + ny]\n",
    "\n",
    "    else:\n",
    "        # if one dim is smaller fill that side up with 0's\n",
    "        slice_cropped = np.zeros((nx, ny))\n",
    "\n",
    "        if x <= nx and y > ny:\n",
    "            # fill up x direction with 0's, cut in y direction\n",
    "            slice_cropped[x_c:x_c + x, :] = image[:, y_s:y_s + ny]\n",
    "        elif x > nx and y <= ny:\n",
    "            # fill up y direction with 0's, cut in x direction\n",
    "            slice_cropped[:, y_c:y_c + y] = image[x_s:x_s + nx, :]\n",
    "        else:\n",
    "            # if dimensions are as desired, keep the original slice\n",
    "            slice_cropped[x_c:x_c + x, y_c:y_c + y] = image[:, :]\n",
    "\n",
    "    return slice_cropped\n",
    "\n",
    "\n",
    "def preprocess(input_folder, target_resolution, target_size, denoise=False, alphaTV=0.2):\n",
    "    '''\n",
    "    This function preprocesses ACDC data. It crops all images to the same size,\n",
    "    transforms everything to the same resolution and normalizes the images.\n",
    "    It automatically makes the folder where preprocessed data is written to,\n",
    "    in the same format as the ACDC data is given. The images are in PNG-format.\n",
    "    If wanted, it can denoise the data as well. It will put this in a different folder.\n",
    "    If you want to have denoised and non-denoised data, run the function twice with denoise\n",
    "    on False and True.\n",
    "    The function outputs the scale vectors and original image sizes so we can transform the masks\n",
    "    back to the original input format.\n",
    "    \n",
    "    input_folder: the folder where raw ACDC data is located.\n",
    "    target_resolution: desired resolution, should be a tuple with 2 items (x- and y-dimensions).\n",
    "    target_size: desired size. Should be a tuple wiht 2 items (x- and y-dimensions).\n",
    "    alphaTV: parameter used in the TV denoising.\n",
    "    '''\n",
    "    nx, ny = target_size\n",
    "    data_folder = input_folder\n",
    "    # i = 0  # iterator for saving original resolution and size\n",
    "    scale_vectors = [[0,0]]\n",
    "    original_image_size = [[0,0]]\n",
    "    \n",
    "    if denoise:\n",
    "        foldername = 'preprocessed_denoised'\n",
    "    else:\n",
    "        foldername = 'preprocessed'\n",
    "    \n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # Loop over train and test folders\n",
    "    for train_test in ['training', 'testing']:\n",
    "\n",
    "        input_folder = os.path.join(data_folder, train_test)\n",
    "        len_inp = len(input_folder)+1\n",
    "        \n",
    "#         if os.path.exists(os.path.join(input_folder+'/'+train_test, '.ipynb_checkpoints')):\n",
    "#             n = len(os.listdir(input_folder)) - 1\n",
    "#         else:\n",
    "#             n = len(os.listdir(input_folder))\n",
    "            \n",
    "#         original_pixel_size = np.zeros((n, 2))\n",
    "#         original_image_size = np.zeros((n, 2))\n",
    "        \n",
    "        # Make train and test folders in preprocessed folder\n",
    "        if not os.path.exists(os.path.join(foldername+'/', train_test)):\n",
    "            os.mkdir(os.path.join(foldername+'/', train_test))\n",
    "        else:\n",
    "            print('T'+train_test[1:]+' folder already exists. Continuing regardless.')\n",
    "        \n",
    "        # Loop over patient folders\n",
    "        for folder in os.listdir(input_folder):\n",
    "            \n",
    "            if folder != '.ipynb_checkpoints':  # Sometimes trouble with automatically made files\n",
    "\n",
    "                folder_path = os.path.join(input_folder, folder)\n",
    "                \n",
    "                # Make patient folders in preprocessed folder\n",
    "                if not os.path.exists(os.path.join(foldername+'/'+train_test, folder_path[len_inp:])):\n",
    "                    os.mkdir(os.path.join(foldername+'/'+train_test, folder_path[len_inp:]))\n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' already exists. Continuing regardless.')\n",
    "                \n",
    "                if os.path.exists(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints'):\n",
    "                    os.rmdir(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints')\n",
    "                    \n",
    "                lst = os.listdir(foldername+'/'+train_test+'/'+folder_path[len_inp:])\n",
    "                \n",
    "                if len(lst) == 0:  # Only create files if the designated folder is empty\n",
    "                    \n",
    "                    for file in glob.glob(os.path.join(folder_path, 'patient???_frame??.nii.gz')):\n",
    "\n",
    "                        # Save information about patient\n",
    "                        with open(os.path.join(folder_path, 'Info.cfg')) as f:\n",
    "                            lines = f.readlines()\n",
    "\n",
    "                        ED = int(lines[0].strip()[-2:])\n",
    "                        ES = int(lines[1].strip()[-2:])\n",
    "\n",
    "                        # Split file name\n",
    "                        file_base = file.split('.nii.gz')[0]\n",
    "                        file_mask = file_base + '_gt.nii.gz'\n",
    "\n",
    "                        # Load data from .nii.gz files\n",
    "                        img_nii = nib.load(file)\n",
    "                        img_dat = img_nii.get_fdata()\n",
    "\n",
    "                        mask_nii = nib.load(file_mask)\n",
    "                        mask_dat = mask_nii.get_fdata()\n",
    "\n",
    "                        img = img_nii.get_fdata()\n",
    "                        mask = mask_nii.get_fdata()\n",
    "\n",
    "                        pixel_size = img_nii.header.get_zooms()\n",
    "                        \n",
    "                        # Save original pixel and image size before transforming\n",
    "                        # original_pixel_size = np.append(original_pixel_size, [[pixel_size[0], pixel_size[1]]], axis = 0)\n",
    "                        original_image_size = np.append(original_image_size, [[img.shape[0], img.shape[1]]], axis=0)\n",
    "                            \n",
    "                        # Make vector to make all images have the same resolution\n",
    "                        scale_vector = [pixel_size[0] / target_resolution[0], pixel_size[1] / target_resolution[1]] \n",
    "                        scale_vectors = np.append(scale_vectors, [scale_vector], axis=0)\n",
    "                        \n",
    "                        print(scale_vectors)\n",
    "                        \n",
    "                        for zz in tqdm.tqdm(range(img.shape[2])):\n",
    "\n",
    "                            # Normalize, rescale and crop the image and  mask\n",
    "\n",
    "                            slice_img = np.squeeze(img[:, :, zz])\n",
    "                            slice_img = normalize_img(np.squeeze(img[:, :, zz]))\n",
    "                            img_rescaled = transform.rescale(slice_img,\n",
    "                                                             scale_vector,\n",
    "                                                             order=1,\n",
    "                                                             preserve_range=True,\n",
    "                                                             mode='constant')\n",
    "\n",
    "                            slice_mask = np.squeeze(mask[:, :, zz])\n",
    "                            \n",
    "                            # slice_mask = normalize_img(np.squeeze(mask[:, :, zz]))\n",
    "                            mask_rescaled = transform.rescale(slice_mask,\n",
    "                                                              scale_vector,\n",
    "                                                              order=0,\n",
    "                                                              preserve_range=True,\n",
    "                                                              mode='constant')\n",
    "\n",
    "                            img_cropped = crop_pad_resize(img_rescaled, nx, ny)\n",
    "                            mask_cropped = crop_pad_resize(mask_rescaled, nx, ny)\n",
    "                            \n",
    "                            if denoise:\n",
    "                                img_cropped = denoise_tv_chambolle(img_cropped, eps=1e-6, weight=alphaTV, max_num_iter=1000)\n",
    "\n",
    "                            # Save images in PNG format\n",
    "                            if 'frame{:02}'.format(ED) in file:\n",
    "                                img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED'.format(zz)+'.png')\n",
    "                                img_fin = Image.fromarray(np.uint8(255 * img_cropped),mode=\"L\")\n",
    "                                img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "                                mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED_gt'.format(zz)+'.png')\n",
    "                                mask_fin = Image.fromarray(np.uint8(mask_cropped), mode=\"L\")\n",
    "                                mask_fin.save(mask_loc, format='PNG')\n",
    "                            else:\n",
    "                                img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES'.format(zz)+'.png')\n",
    "                                img_fin = Image.fromarray(np.uint8(255 * img_cropped), mode=\"L\")\n",
    "                                img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "                                mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES_gt'.format(zz)+'.png')\n",
    "                                mask_fin = Image.fromarray(np.uint8(mask_cropped),mode=\"L\")\n",
    "                                mask_fin.save(mask_loc, format='PNG')\n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' is not empty. No files were written to this folder.')\n",
    "    \n",
    "    return scale_vectors, original_image_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbca9d3-6919-4562-b86c-dd2e32944bac",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c785ee5-f3a6-4c21-a1bc-ab3776dca597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed folder already exists. Continuing regardless.\n",
      "Training folder already exists. Continuing regardless.\n",
      "Folder for patient001 already exists. Continuing regardless.\n",
      "[[0.         0.        ]\n",
      " [1.14285505 1.14285505]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:00<00:00, 52.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n",
      "[0. 1. 2. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 52.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3.]\n",
      "Testing folder already exists. Continuing regardless.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_resolution = (1.36719, 1.36719)\n",
    "target_size = (212, 212)\n",
    "data_path = 'dummy_data'\n",
    "\n",
    "scale_vectors, original_image_size = preprocess(data_path, target_resolution, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e93f27-2536-46ec-bcf0-50213e07a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.        ]\n",
      " [1.14285505 1.14285505]]\n",
      "[[  0   0]\n",
      " [216 256]]\n"
     ]
    }
   ],
   "source": [
    "print(scale_vectors)\n",
    "\n",
    "print(original_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240090-a4ba-43d3-838d-78462f1f2e9a",
   "metadata": {},
   "source": [
    "#### Denoise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc831d0-c58b-492d-bac7-dbdf0d0f6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(data_path, target_resolution, target_size, denoise=True, alphaTV=0.2)\n",
    "# alpha = 0.1 geeft wel prima maar nog veel details, 0.3 is misschien net hoog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7ebf5-759d-4413-84cb-f79a64611111",
   "metadata": {},
   "source": [
    "### Back to original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18d164df-3296-4013-b53d-8b362c0c9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtoformat(scale_vectors, original_image_size, mask_folder):\n",
    "    '''\n",
    "    scale_vectors: the vectors that were used in preprocessing to reach desired\n",
    "        resolution\n",
    "    original_image_size: the orginal sizes of the images\n",
    "    mask_folder: the folder where the masks (output from network) are located\n",
    "    '''\n",
    "    \n",
    "    foldername = 'finalmasks'\n",
    "    prev_file = '00000000000'\n",
    "    i = -1\n",
    "    \n",
    "    # make folder if it doesn't exist yet\n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # remove automatically made files\n",
    "    if os.path.exists(os.path.join(mask_folder, '.ipynb_checkpoints')):\n",
    "        os.rmdir(os.path.join(mask_folder, '.ipynb_checkpoints'))\n",
    "    \n",
    "    # only write files if the folder is empty\n",
    "    if len(os.listdir(foldername)) == 0:\n",
    "        # loop over masks\n",
    "        for file in os.listdir(mask_folder):\n",
    "\n",
    "            # update iterator if we go to the next patient\n",
    "            if prev_file[:11] != file[:11]:\n",
    "                i += 1\n",
    "\n",
    "            px, py = scale_vectors[i]\n",
    "            nx, ny = original_image_size[i]\n",
    "\n",
    "            file_path = os.path.join(mask_folder, file)\n",
    "            \n",
    "            mask = Image.open(file_path).convert('L')\n",
    "            mask = np.array(mask, dtype=np.uint8)\n",
    "            print(np.unique(mask))\n",
    "            scale_vector = [1/px, 1/py]\n",
    "\n",
    "            # pad or crop \n",
    "            mask = crop_pad_resize(mask, nx, ny)\n",
    "            \n",
    "            # scale back\n",
    "            mask = transform.rescale(mask,\n",
    "                                     scale_vector,\n",
    "                                     order=0,\n",
    "                                     preserve_range=True,\n",
    "                                     mode='constant')\n",
    "\n",
    "            \n",
    "\n",
    "            # save file\n",
    "            mask_loc = os.path.join(foldername, file)\n",
    "            mask_fin = Image.fromarray(np.uint8(mask), mode=\"L\")\n",
    "            \n",
    "            mask_fin.save(mask_loc, format='PNG')\n",
    "            prev_file = file\n",
    "    else:\n",
    "        print(foldername+' folder was not empty. No files were written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "096ca421-baa3-4ffd-b15d-c1d0f6b62c79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0]\n",
      "[0]\n",
      "[0]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "mask_folder = 'dummy_masks'\n",
    "scale_vectors = [[0, 0]]\n",
    "scale_vectors = np.append(scale_vectors, [[1.14285505, 1.14285505]], axis=0)\n",
    "original_image_size = [[0, 0]]\n",
    "original_image_size = np.append(original_image_size, [[216, 256]], axis=0)\n",
    "\n",
    "backtoformat(scale_vectors[1:], original_image_size[1:], mask_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
