{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e146f34-847a-4370-93dd-6e6efbaad913",
   "metadata": {},
   "source": [
    "# Preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7fe633c-5b3f-446b-bd9f-77fbb588b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import transform\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "\n",
    "def normalize_img(img):\n",
    "    # Warning for when dividing NaN value??\n",
    "    norm_img = np.divide(img,np.max(img))\n",
    "    return norm_img\n",
    "\n",
    "\n",
    "def crop_pad_resize(image, nx, ny):\n",
    "    '''\n",
    "    Code from Christian F. Baumgartner and Lisa M. Koch from\n",
    "    \"An Exploration of 2D and 3D Deep Learning Techniques for\n",
    "    Cardiac MR Image Segmentation\" (2017).\n",
    "    Comments by us.\n",
    "    '''\n",
    "    x, y = image.shape\n",
    "\n",
    "    # difference in nr of pixels (divide by 2 since we have 2 sides)\n",
    "    x_s = (x - nx) // 2\n",
    "    y_s = (y - ny) // 2\n",
    "    x_c = (nx - x) // 2\n",
    "    y_c = (ny - y) // 2\n",
    "\n",
    "    if x > nx and y > ny:\n",
    "        # if image is larger in both dimensions cut a slice\n",
    "        slice_cropped = image[x_s:x_s + nx, y_s:y_s + ny]\n",
    "\n",
    "    else:\n",
    "        # if one dim is smaller fill that side up with 0's\n",
    "        slice_cropped = np.zeros((nx, ny))\n",
    "\n",
    "        if x <= nx and y > ny:\n",
    "            # fill up x direction with 0's, cut in y direction\n",
    "            slice_cropped[x_c:x_c + x, :] = image[:, y_s:y_s + ny]\n",
    "        elif x > nx and y <= ny:\n",
    "            # fill up y direction with 0's, cut in x direction\n",
    "            slice_cropped[:, y_c:y_c + y] = image[x_s:x_s + nx, :]\n",
    "        else:\n",
    "            # if dimensions are as desired, keep the original slice\n",
    "            slice_cropped[x_c:x_c + x, y_c:y_c + y] = image[:, :]\n",
    "\n",
    "    return slice_cropped\n",
    "\n",
    "\n",
    "def preprocess(input_folder, target_resolution, target_size, denoise=False, alphaTV=0.2):\n",
    "    '''\n",
    "    This function preprocesses ACDC data. It crops all images to the same size,\n",
    "    transforms everything to the same resolution and normalizes the images.\n",
    "    It automatically makes the folder where preprocessed data is written to,\n",
    "    in the same format as the ACDC data is given. The images are in PNG-format.\n",
    "    If wanted, it can denoise the data as well. It will put this in a different folder.\n",
    "    If you want to have denoised and non-denoised data, run the function twice with denoise\n",
    "    on False and True.\n",
    "    The function outputs the scale vectors and original image sizes so we can transform the masks\n",
    "    back to the original input format.\n",
    "    \n",
    "    input_folder: the folder where raw ACDC data is located.\n",
    "    target_resolution: desired resolution, should be a tuple with 2 items (x- and y-dimensions).\n",
    "    target_size: desired size. Should be a tuple wiht 2 items (x- and y-dimensions).\n",
    "    alphaTV: parameter used in the TV denoising.\n",
    "    '''\n",
    "    nx, ny = target_size\n",
    "    data_folder = input_folder\n",
    "    # i = 0  # iterator for saving original resolution and size\n",
    "    scale_vectors = [[0, 0]]\n",
    "    original_image_size = [[0, 0]]\n",
    "    \n",
    "    if denoise:\n",
    "        foldername = 'preprocessed_denoised'\n",
    "    else:\n",
    "        foldername = 'preprocessed'\n",
    "    \n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # Loop over train and test folders\n",
    "    for train_test in ['training', 'testing']:\n",
    "\n",
    "        input_folder = os.path.join(data_folder, train_test)\n",
    "        len_inp = len(input_folder)+1\n",
    "        \n",
    "#         if os.path.exists(os.path.join(input_folder+'/'+train_test, '.ipynb_checkpoints')):\n",
    "#             n = len(os.listdir(input_folder)) - 1\n",
    "#         else:\n",
    "#             n = len(os.listdir(input_folder))\n",
    "            \n",
    "#         original_pixel_size = np.zeros((n, 2))\n",
    "#         original_image_size = np.zeros((n, 2))\n",
    "        \n",
    "        # Make train and test folders in preprocessed folder\n",
    "        if not os.path.exists(os.path.join(foldername+'/', train_test)):\n",
    "            os.mkdir(os.path.join(foldername+'/', train_test))\n",
    "        else:\n",
    "            print('T'+train_test[1:]+' folder already exists. Continuing regardless.')\n",
    "        \n",
    "        # Loop over patient folders\n",
    "        for folder in os.listdir(input_folder):\n",
    "            \n",
    "            if folder != '.ipynb_checkpoints':  # Sometimes trouble with automatically made files\n",
    "\n",
    "                folder_path = os.path.join(input_folder, folder)\n",
    "                \n",
    "                # Make patient folders in preprocessed folder\n",
    "                if not os.path.exists(os.path.join(foldername+'/'+train_test, folder_path[len_inp:])):\n",
    "                    os.mkdir(os.path.join(foldername+'/'+train_test, folder_path[len_inp:]))\n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' already exists. Continuing regardless.')\n",
    "                \n",
    "                if os.path.exists(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints'):\n",
    "                    os.rmdir(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints')\n",
    "                    \n",
    "                lst = os.listdir(foldername+'/'+train_test+'/'+folder_path[len_inp:])\n",
    "                \n",
    "                if len(lst) == 0:  # Only create files if the designated folder is empty\n",
    "                    \n",
    "                    for file in glob.glob(os.path.join(folder_path, 'patient???_frame??.nii.gz')):\n",
    "\n",
    "                        # Save information about patient\n",
    "                        with open(os.path.join(folder_path, 'Info.cfg')) as f:\n",
    "                            lines = f.readlines()\n",
    "\n",
    "                        ED = int(lines[0].strip()[-2:])\n",
    "                        ES = int(lines[1].strip()[-2:])\n",
    "\n",
    "                        # Split file name\n",
    "                        file_base = file.split('.nii.gz')[0]\n",
    "                        file_mask = file_base + '_gt.nii.gz'\n",
    "\n",
    "                        # Load data from .nii.gz files\n",
    "                        img_nii = nib.load(file)\n",
    "                        img_dat = img_nii.get_fdata()\n",
    "\n",
    "                        mask_nii = nib.load(file_mask)\n",
    "                        mask_dat = mask_nii.get_fdata()\n",
    "\n",
    "                        img = img_nii.get_fdata()\n",
    "                        mask = mask_nii.get_fdata()\n",
    "\n",
    "                        pixel_size = img_nii.header.get_zooms()\n",
    "                        \n",
    "                        # Save original pixel and image size before transforming\n",
    "                        # original_pixel_size = np.append(original_pixel_size, [[pixel_size[0], pixel_size[1]]], axis = 0)\n",
    "                        original_image_size = np.append(original_image_size, [[img.shape[0], img.shape[1]]], axis=0)\n",
    "                            \n",
    "                        # Make vector to make all images have the same resolution\n",
    "                        scale_vector = [pixel_size[0] / target_resolution[0], pixel_size[1] / target_resolution[1]] \n",
    "                        scale_vectors = np.append(scale_vectors, [scale_vector], axis=0)\n",
    "                        \n",
    "                        for zz in tqdm.tqdm(range(img.shape[2])):\n",
    "\n",
    "                            # Normalize, rescale and crop the image and  mask\n",
    "\n",
    "                            slice_img = np.squeeze(img[:, :, zz])\n",
    "                            slice_img = normalize_img(np.squeeze(img[:, :, zz]))\n",
    "                            img_rescaled = transform.rescale(slice_img,\n",
    "                                                             scale_vector,\n",
    "                                                             order=1,\n",
    "                                                             preserve_range=True,\n",
    "                                                             mode='constant')\n",
    "\n",
    "                            slice_mask = np.squeeze(mask[:, :, zz])\n",
    "                            \n",
    "                            # slice_mask = normalize_img(np.squeeze(mask[:, :, zz]))\n",
    "                            mask_rescaled = transform.rescale(slice_mask,\n",
    "                                                              scale_vector,\n",
    "                                                              order=0,\n",
    "                                                              preserve_range=True,\n",
    "                                                              mode='constant')\n",
    "\n",
    "                            img_cropped = crop_pad_resize(img_rescaled, nx, ny)\n",
    "                            mask_cropped = crop_pad_resize(mask_rescaled, nx, ny)\n",
    "                            \n",
    "                            if denoise:\n",
    "                                img_cropped = denoise_tv_chambolle(img_cropped, eps=1e-6, weight=alphaTV, max_num_iter=1000)\n",
    "\n",
    "                            # Save images in PNG format\n",
    "                            if 'frame{:02}'.format(ED) in file:\n",
    "                                img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED'.format(zz)+'.png')\n",
    "                                img_fin = Image.fromarray(np.uint8(255 * img_cropped),mode=\"L\")\n",
    "                                img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "                                mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ED_gt'.format(zz)+'.png')\n",
    "                                mask_fin = Image.fromarray(np.uint8(mask_cropped), mode=\"L\")\n",
    "                                mask_fin.save(mask_loc, format='PNG')\n",
    "                            else:\n",
    "                                img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES'.format(zz)+'.png')\n",
    "                                img_fin = Image.fromarray(np.uint8(255 * img_cropped), mode=\"L\")\n",
    "                                img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "                                mask_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:01}_ES_gt'.format(zz)+'.png')\n",
    "                                mask_fin = Image.fromarray(np.uint8(mask_cropped),mode=\"L\")\n",
    "                                mask_fin.save(mask_loc, format='PNG')\n",
    "                    \n",
    "                else:\n",
    "                    print('Folder for '+folder_path[len_inp:]+' is not empty. No files were written to this folder.')\n",
    "    \n",
    "    scale_vectors = np.delete(scale_vectors, 0, axis=0)\n",
    "    original_image_size = np.delete(original_image_size, 0, axis=0)\n",
    "    \n",
    "    return scale_vectors, original_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "456bd615-b312-41a7-84f5-5db03801a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def secret_preprocess(input_folder, target_resolution, target_size, denoise=False, alphaTV=0.2):\n",
    "    '''\n",
    "    This function preprocesses ACDC data. It crops all images to the same size,\n",
    "    transforms everything to the same resolution and normalizes the images.\n",
    "    It automatically makes the folder where preprocessed data is written to,\n",
    "    in the same format as the ACDC data is given. The images are in PNG-format.\n",
    "    If wanted, it can denoise the data as well. It will put this in a different folder.\n",
    "    If you want to have denoised and non-denoised data, run the function twice with denoise\n",
    "    on False and True.\n",
    "    The function outputs the scale vectors and original image sizes so we can transform the masks\n",
    "    back to the original input format.\n",
    "    \n",
    "    input_folder: the folder where raw ACDC data is located.\n",
    "    target_resolution: desired resolution, should be a tuple with 2 items (x- and y-dimensions).\n",
    "    target_size: desired size. Should be a tuple wiht 2 items (x- and y-dimensions).\n",
    "    alphaTV: parameter used in the TV denoising.\n",
    "    '''\n",
    "    nx, ny = target_size\n",
    "    data_folder = input_folder\n",
    "    # i = 0  # iterator for saving original resolution and size\n",
    "    scale_vectors = [[0, 0]]\n",
    "    original_image_size = [[0, 0]]\n",
    "    \n",
    "    if denoise:\n",
    "        foldername = 'preprocessed_denoised'\n",
    "    else:\n",
    "        foldername = 'secret_preprocessed'\n",
    "    \n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # Loop over train and test folders\n",
    "    train_test = 'secret_test'\n",
    "\n",
    "    input_folder = os.path.join(data_folder, train_test)\n",
    "    len_inp = len(input_folder)+1\n",
    "\n",
    "    # Make train and test folders in preprocessed folder\n",
    "    if not os.path.exists(os.path.join(foldername+'/', train_test)):\n",
    "        os.mkdir(os.path.join(foldername+'/', train_test))\n",
    "    else:\n",
    "        print('T'+train_test[1:]+' folder already exists. Continuing regardless.')\n",
    "\n",
    "    # Loop over patient folders\n",
    "    for i, folder in enumerate(os.listdir(input_folder)):\n",
    "\n",
    "        if folder != '.ipynb_checkpoints':  # Sometimes trouble with automatically made files\n",
    "\n",
    "            folder_path = os.path.join(input_folder, folder)\n",
    "\n",
    "            # Make patient folders in preprocessed folder\n",
    "            if not os.path.exists(os.path.join(foldername+'/'+train_test, folder_path[len_inp:])):\n",
    "                os.mkdir(os.path.join(foldername+'/'+train_test, folder_path[len_inp:]))\n",
    "            else:\n",
    "                print('Folder for '+folder_path[len_inp:]+' already exists. Continuing regardless.')\n",
    "\n",
    "            if os.path.exists(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints'):\n",
    "                os.rmdir(foldername+'/'+train_test+'/'+folder_path[len_inp:]+'/.ipynb_checkpoints')\n",
    "\n",
    "            lst = os.listdir(foldername+'/'+train_test+'/'+folder_path[len_inp:])\n",
    "\n",
    "            if len(lst) == 0:  # Only create files if the designated folder is empty\n",
    "\n",
    "                for file in glob.glob(os.path.join(folder_path, 'patient???_frame??.nii.gz')):\n",
    "                    # Load data from .nii.gz files\n",
    "                    img_nii = nib.load(file)\n",
    "                    img = img_nii.get_fdata()\n",
    "                    \n",
    "                    # Take the slices of the i'th patient (out of the 25)\n",
    "                    img = img[:,:,:,i]\n",
    "                    \n",
    "                    pixel_size = img_nii.header.get_zooms()\n",
    "\n",
    "                    # Save original pixel and image size before transforming\n",
    "                    original_image_size = np.append(original_image_size, [[img.shape[0], img.shape[1]]], axis=0)\n",
    "\n",
    "                    # Make vector to make all images have the same resolution\n",
    "                    scale_vector = [pixel_size[0] / target_resolution[0], pixel_size[1] / target_resolution[1]]\n",
    "                    scale_vectors = np.append(scale_vectors, [scale_vector], axis=0)\n",
    "\n",
    "                    for sliice in tqdm.tqdm(range(img.shape[2])):\n",
    "\n",
    "                        # Normalize, rescale and crop the image and  mask\n",
    "                        slice_img = np.squeeze(img[:, :, sliice])\n",
    "                        slice_img = normalize_img(np.squeeze(img[:, :, sliice]))\n",
    "                        img_rescaled = transform.rescale(slice_img,\n",
    "                                                         scale_vector,\n",
    "                                                         order=1,\n",
    "                                                         preserve_range=True,\n",
    "                                                         mode='constant')\n",
    "\n",
    "                        img_cropped = crop_pad_resize(img_rescaled, nx, ny)\n",
    "\n",
    "                        if denoise:\n",
    "                            img_cropped = denoise_tv_chambolle(img_cropped, eps=1e-6, weight=alphaTV, max_num_iter=1000)\n",
    "\n",
    "                        # Save images in PNG format\n",
    "                        img_loc = os.path.join(foldername+'/'+train_test, file[len_inp:-7]+'_slice{:02}'.format(sliice)+'.png')\n",
    "                        img_fin = Image.fromarray(np.uint8(255 * img_cropped),mode=\"L\")\n",
    "                        img_fin.save(img_loc, format='PNG')\n",
    "\n",
    "            else:\n",
    "                print('Folder for '+folder_path[len_inp:]+' is not empty. No files were written to this folder.')\n",
    "    \n",
    "    scale_vectors = np.delete(scale_vectors, 0, axis=0)\n",
    "    original_image_size = np.delete(original_image_size, 0, axis=0)\n",
    "    \n",
    "    return scale_vectors, original_image_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbca9d3-6919-4562-b86c-dd2e32944bac",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c785ee5-f3a6-4c21-a1bc-ab3776dca597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 69.27it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 66.81it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 64.80it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 71.99it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 106.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 128.76it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 117.59it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 82.65it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 61.27it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 132.07it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 100.65it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 98.29it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 122.50it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 114.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 110.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 108.27it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 118.89it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 106.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 114.49it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 107.12it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 122.61it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 155.81it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 120.00it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 32.48it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 120.63it/s]\n"
     ]
    }
   ],
   "source": [
    "target_resolution = (1.36719, 1.36719)\n",
    "target_size = (256, 256)\n",
    "data_path = '../ACDC/database/'\n",
    "\n",
    "scale_vectors, original_image_size = secret_preprocess(data_path, target_resolution, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788acd3e-e391-4dfe-a5c3-4922feab0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_vectors, original_imsize = preprocess(data_path, target_resolution, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a3e93f27-2536-46ec-bcf0-50213e07a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.14285505 1.14285505]\n",
      " [0.99999817 0.99999817]]\n",
      "[[216 256]\n",
      " [232 256]]\n"
     ]
    }
   ],
   "source": [
    "print(scale_vectors)\n",
    "\n",
    "print(original_image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a240090-a4ba-43d3-838d-78462f1f2e9a",
   "metadata": {},
   "source": [
    "#### Denoise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc831d0-c58b-492d-bac7-dbdf0d0f6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(data_path, target_resolution, target_size, denoise=True, alphaTV=0.2)\n",
    "# alpha = 0.1 geeft wel prima maar nog veel details, 0.3 is misschien net hoog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7ebf5-759d-4413-84cb-f79a64611111",
   "metadata": {},
   "source": [
    "### Back to original format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "18d164df-3296-4013-b53d-8b362c0c9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtoformat(scale_vectors, original_image_size, mask_folder):\n",
    "    '''\n",
    "    scale_vectors: the vectors that were used in preprocessing to reach desired\n",
    "        resolution\n",
    "    original_image_size: the orginal sizes of the images\n",
    "    mask_folder: the folder where the masks (output from network) are located\n",
    "    '''\n",
    "    \n",
    "    foldername = 'finalmasks'\n",
    "    prev_file = '00000000000'  # so that the first new_patient is always true\n",
    "    i = -1\n",
    "    new_patient = True\n",
    "\n",
    "    # make folder if it doesn't exist yet\n",
    "    if not os.path.exists(foldername):\n",
    "        os.mkdir(foldername)\n",
    "    else:\n",
    "        print(foldername+' folder already exists. Continuing regardless.')\n",
    "    \n",
    "    # remove automatically made files\n",
    "    if os.path.exists(os.path.join(mask_folder, '.ipynb_checkpoints')):\n",
    "        os.rmdir(os.path.join(mask_folder, '.ipynb_checkpoints'))\n",
    "    \n",
    "    # only write files if the folder is empty\n",
    "    if len(os.listdir(foldername)) == 0:\n",
    "        # loop over masks\n",
    "        for file in sorted(os.listdir(mask_folder)):\n",
    "            \n",
    "            # update iterator if we go to the next patient\n",
    "            if prev_file[:11] != file[:11]:\n",
    "                i += 1\n",
    "                new_patient = True\n",
    "            else:\n",
    "                new_patient = False\n",
    "\n",
    "            px, py = scale_vectors[i][0], scale_vectors[i][1]\n",
    "            nx, ny = original_image_size[i][0], original_image_size[i][1]\n",
    "\n",
    "            file_path = os.path.join(mask_folder, file)\n",
    "            \n",
    "            mask = Image.open(file_path).convert('L')\n",
    "            mask = np.array(mask, dtype=np.uint8)\n",
    "            \n",
    "            scale_vector = [1/px, 1/py]\n",
    "            \n",
    "            # scale back\n",
    "            mask = transform.rescale(mask,\n",
    "                                     scale_vector,\n",
    "                                     order=0,\n",
    "                                     preserve_range=True,\n",
    "                                     mode='constant')\n",
    "            \n",
    "            # pad or crop back\n",
    "            mask = crop_pad_resize(mask, nx, ny)\n",
    "            \n",
    "            if new_patient:\n",
    "                if i > 0:\n",
    "                    # save the previous 3D np array (if there is one)\n",
    "                    niftimage = nib.Nifti1Image(threedimage, affine=np.eye(4))\n",
    "                    nib.save(niftimage, os.path.join('finalmasks', prev_file[:-17]+'_gt'+'.nii.gz'))\n",
    "                # if we have a new page, make new np array for new nii.gz file\n",
    "                threedimage = mask.reshape(nx, ny, 1)\n",
    "\n",
    "            else:\n",
    "                # add mask to 3D np array\n",
    "                mask_threed = mask.reshape(nx, ny, 1)\n",
    "                threedimage = np.concatenate([threedimage, mask_threed], 2)\n",
    "\n",
    "\n",
    "            # save file as PNG if wanted\n",
    "#             mask_loc = os.path.join(foldername, file)\n",
    "#             mask_fin = Image.fromarray(np.uint8(mask), mode=\"L\")\n",
    "            \n",
    "#             mask_fin.save(mask_loc, format='PNG')\n",
    "            prev_file = file\n",
    "        \n",
    "        # save last 3D np array\n",
    "        niftimage = nib.Nifti1Image(threedimage, affine=np.eye(4))\n",
    "        nib.save(niftimage, os.path.join('finalmasks', prev_file[:-17]+'_gt'+'.nii.gz'))\n",
    "    else:\n",
    "        print(foldername+' folder was not empty. No files were written.')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "096ca421-baa3-4ffd-b15d-c1d0f6b62c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_folder = 'dummy_masks'\n",
    "\n",
    "backtoformat(scale_vectors, original_image_size, mask_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defa40b5-ba04-493e-a527-1ea4b41e50f8",
   "metadata": {},
   "source": [
    "#### Test if saving as nii.gz went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "cf8b5e9e-024b-4f90-8262-1f06d6777193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 256, 10)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'finalmasks/patient001_frame01_gt.nii.gz'\n",
    "img_nii = nib.load(file)\n",
    "img = img_nii.get_fdata()\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb914f9-6917-4297-a552-c4a8e121a387",
   "metadata": {},
   "source": [
    "### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7233c008-112e-4d1d-ac9c-dbf59590398e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n",
      "finalmasks/patient001_frame01_gt.nii.gz\n"
     ]
    }
   ],
   "source": [
    "for file in sorted(os.listdir('dummy_masks')):\n",
    "    print(os.path.join('finalmasks', file[:-17]+'_gt'+'.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "208ce3ac-32e0-4520-be0c-5b5988909993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 256, 1)\n",
      "(216, 256, 1)\n",
      "(216, 256, 2)\n",
      "(216, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "nx, ny = (216, 256)\n",
    "threedimage = np.zeros((nx, ny, 1), int)\n",
    "print(threedimage.shape)\n",
    "mask = np.ones(216*256)\n",
    "mask_threed = mask.reshape(nx, ny, 1)\n",
    "print(mask_threed.shape)\n",
    "\n",
    "threedimage = np.concatenate([threedimage, mask_threed], 2)\n",
    "print(threedimage.shape)\n",
    "\n",
    "again = np.concatenate([threedimage, mask_threed], 2)\n",
    "print(again.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b200aeeb-9faa-4c9d-9624-e5603a57de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4, 3)\n",
      "(3, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "a1 = np.zeros((3, 4, 1), dtype=np.uint8)\n",
    "\n",
    "a2 = np.full((3, 4, 1), 2, dtype=np.uint8)\n",
    "\n",
    "x = np.concatenate([a1, a2], 2)\n",
    "\n",
    "a3 = np.full((3, 4, 1), 3, dtype=np.uint8)\n",
    "\n",
    "y = np.concatenate([x, a3], 2)\n",
    "print(y.shape)\n",
    "\n",
    "y = np.delete(y, 0, axis=2)\n",
    "print(y.shape)\n",
    "\n",
    "# x = np.arange(4*4*3).reshape(4,4,3)\n",
    "# print(x.shape)\n",
    "# ni_img = nib.Nifti1Image(x, affine=np.eye(4))\n",
    "# niftimage = nib.Nifti1Image(y, affine=np.eye(4))\n",
    "\n",
    "# nib.save(niftimage, os.path.join('finalmasks', 'test3d.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "97975c18-4f04-4acf-88c8-7687ee78bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(4, 2)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "y = [[0, 0]]\n",
    "y = np.append(scale_vectors, [[1.14285505, 1.14285505]], axis=0)\n",
    "x = [[0, 0]]\n",
    "x = np.append(original_image_size, [[216, 256]], axis=0)\n",
    "\n",
    "print(y.shape)\n",
    "print(x.shape)\n",
    "\n",
    "y = np.delete(y, 0, axis=1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "46c5fb98-40de-4269-8171-b6c41f72e076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1428550530650459\n",
      "1.1428550530650459\n"
     ]
    }
   ],
   "source": [
    "x, y = scale_vectors[0][0], scale_vectors[0][1]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "15743791-071b-42b7-9144-19c8d21c1bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.14285505, 1.14285505],\n",
       "       [0.99999817, 0.99999817]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93a2c3-3209-4301-9d72-e1c6666c479a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
